services:
  tgi-server:
    image: tgi_gaudi:mh-test
    container_name: tgi-server
    ports:
      - "8085:80"
    volumes:
      - ${HF_CACHE_DIR}:/data
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      HUGGING_FACE_HUB_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
      # HF_HUB_DISABLE_PROGRESS_BARS: 1
      # HF_HUB_ENABLE_HF_TRANSFER: 0
      HABANA_VISIBLE_DEVICES: 0,1,2,3
      OMPI_MCA_btl_vader_single_copy_mechanism: none
      TEXT_GENERATION_SERVER_IGNORE_EOS_TOKEN: true
      PT_HPU_ENABLE_LAZY_COLLECTIVES: true
      ENABLE_HPU_GRAPH: true
      LIMIT_HPU_GRAPH: true
      USE_FLASH_ATTENTION: true
      FLASH_ATTENTION_RECOMPUTE: true
    runtime: habana
    cap_add:
      - SYS_NICE
    ipc: host
    command: --model-id ${LLM_MODEL_ID} --max-input-length 16384 --max-total-tokens 32768 --sharded true --num-shard 4 #--max-batch-prefill-tokens 16384 --max-batch-total-tokens 262144 --max-waiting-tokens 7 --waiting-served-ratio 1.2 --max-concurrent-requests 512